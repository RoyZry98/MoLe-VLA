# MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation
![Python 3.8](https://img.shields.io/badge/Python-3.8-blue)
[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://ojs.aaai.org/index.php/AAAI/article/download/29622/31055)
 

<img src="mole.png"/>


Quickly start:
```
cd /path/to/MoLE_VLA
conda env create -f environment.yml
bash train_multi_task10_mix.sh 14 0.5 0.1 0.5 32 0.999 0,1,2,3,4,5,6,7
```
